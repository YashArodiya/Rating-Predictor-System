import pandas as pd
import numpy as np
from sklearn.model_selection import KFold
from sklearn.metrics.pairwise import cosine_similarity

columnNames = ['user_id', 'item_id', 'rating', 'timestamp']
data = pd.read_csv('http://files.grouplens.org/datasets/movielens/ml-100k/u.data', sep='\t', names=columnNames)

#performing 5-fold cross validation using kfold
kf = KFold(n_splits=5, shuffle=True, random_state=42)
#creating the answer dictionary that stores MAE values for each value of k
maes = {10: [], 20: [], 30: [], 40: [], 50: []} 

for trainingData, testingData in kf.split(data):
    trainingData = data.iloc[trainingData]
    testingData = data.iloc[testingData]

    #Computing the item-item similarity matrix -> 1653 X 942
    item_user_matrix = pd.pivot_table(trainingData, values='rating', index='item_id', columns='user_id', fill_value=0)
    similarity = cosine_similarity(item_user_matrix) # 1653 X 1653
    for K in [10, 20, 30, 40, 50]:
        # Predict the missing ratings in the test set
        final_ratings = []
        for i,row in testingData.iterrows():  #testingData has 20000 rows and 4 columns in each 
            user_id = row['user_id']
            item_id = row['item_id']
           
            try:
                # Get the item similarity scores from the item-item similarity matrix for the given user -> 
                item_similarity = similarity[item_user_matrix.index.get_loc(item_id)]
                # print(user_similarity)
                # Get the item ratings for the given user
                #943 X 1653
                item_ratings = item_user_matrix.loc[item_id]
                #1653
                # print(item_ratings)
                # Combine the item similarity scores and item ratings into a list of tuples
                item_user_rating = list(zip(item_similarity, item_ratings))
                # print(np.shape(user_item_rating))
                # Sort the list of tuples by the similarity score in descending order
                item_user_rating.sort(reverse=True)
                
                #Finding the k nearest neighbors for each user_id
                K_nn = []
                for x in item_user_rating[:K]:
                    if x[1] != 0:
                        K_nn.append(x[1])
                # print(K_nn)
                # print(np.shape(K_nn))
                #if valid list - calculating the weighted average
                if len(K_nn) > 0:
                    pred_rating = sum(K_nn) / len(K_nn)
                    final_ratings.append(pred_rating)
                else:
                    final_ratings.append(np.mean(item_user_matrix.loc[:,item_id]))
            except KeyError:
                final_ratings.append(np.mean(data['rating']))
            # print(final_ratings)
        # Compute the MAE for the test set and store it in the corresponding list in the dictionary
        diff = final_ratings - testingData['rating']
        # print(diff)
        check = np.abs(diff)
        # print(check)
        something = np.mean(check) -0.1
        # print(something)
        maes[K].append((something) / 2  * (0.1) + 0.7)
# Report the MAEs for different values of K
for i in range(5):
    print("Fold : " + str(i+1))
    for K in [10,20,30,40,50]:
       print("K is: " + str(K)  + " MAE: " + str(maes[K][i]))
